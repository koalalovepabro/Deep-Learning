{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "08. 미니배치 학습",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/koalalovepabro/Deep-Learning/blob/main/08_%EB%AF%B8%EB%8B%88%EB%B0%B0%EC%B9%98_%ED%95%99%EC%8A%B5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrHsxGCQbqr4"
      },
      "source": [
        "# 배치란?\n",
        "* 입력한 데이터의 묶음\n",
        "* 묶음대로 결과물이 나온다.\n",
        "  - 100개 데이터를 한꺼번에 묶어서( 배치를 만들어서 ) 입력을 했으면,\n",
        "  - 거기에 대한 결과물도 100개가 한꺼번에 나온다.\n",
        "* Loss도 배치를 사용하는 상황에 대해서 대응을 해줘야 한다.\n",
        "  - `N`건의 배치에 대한 loss를 각각 구한다음\n",
        "  - 그 값을 모두 더해서 평균을 내면 된다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9xAszYiduez"
      },
      "source": [
        "# 미니배치란?\n",
        " - 가지고 있는 데이터가 10억건이다.\n",
        " - 과연 신경망이 10억을 모두 사용해서 학습을 하고, 신경망을 평가 할 때 10억건에 대한 모든 손실 함수를 구해서 평균을 구할 필요가 있을까?\n",
        " - 1억건만 써도 충분할 거 같은데....\n",
        " - 데이터의 양이 굉장히 많은 경우에는 모든 데이터를 다 쓰는 것이 아니고,\n",
        " - **데이터의 일부를 무작위로 추려서** 그 근사치로 이용할 수 있다.\n",
        " - 이 일부가 되는 데이터를 **미니배치**라고 한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmFWrdLEei6K"
      },
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_eXMATAre1bc"
      },
      "source": [
        "# mnist 데이터셋 로딩\n",
        "from tensorflow.keras import datasets\n",
        "mnist = datasets.mnist\n",
        "\n",
        "(X_train, y_train), _ = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6s--v5XfBw6",
        "outputId": "689e27a6-267f-423e-c631-8b416c385e66"
      },
      "source": [
        "# 데이터 형상 확인 및 전처리\n",
        "print(\"X_train의 shape : {}\".format(X_train.shape))\n",
        "print(\"y_train의 shape : {}\".format(y_train.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train의 shape : (60000, 28, 28)\n",
            "y_train의 shape : (60000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLY-BpgLfR6U",
        "outputId": "874e3aa5-221c-4ace-8233-93bbfdc086e4"
      },
      "source": [
        "# 데이터 평탄화\n",
        "TRAIN_IMAGE_COUNT = X_train.shape[0]\n",
        "X_train = X_train.reshape(TRAIN_IMAGE_COUNT, -1)\n",
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4dUHTowfjkC"
      },
      "source": [
        "y_train의 형상이 `(60000, )`. One Hot Encoding이 되어있지 않은 상태"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwTR_5o6f7TX"
      },
      "source": [
        "y_train = tf.one_hot(y_train, 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "489AM-gwgd8e"
      },
      "source": [
        "y_train = y_train.numpy() # Tensor 배열을 ndarray 화 시키기"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47Fn7Ev-gndv",
        "outputId": "59f8567b-3b73-4357-c001-5e70432fa569"
      },
      "source": [
        "y_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [1., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 1., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gyC3eVBkgoX3"
      },
      "source": [
        "각 알고리즘( CNN, RNN, ANN )등을 사용할 때마다 받아 들일 수 있는 데이터의 형상(shape)이 상이 하기 때문에 언제나 데이터의 shape을 확인하고 전처리 할 수 있도록 해야 한다.\n",
        "\n",
        "정답 데이터(t) 같은 경우에는 텐서플로우나 파이토치 등의 프레임워크를 사용 할 때는 딱히 신경을 쓰지 않아도 좋다. 단, t의 형상에 따라서 사용되어지는 loss 함수의 종류는 달라질 수 있다.\n",
        "\n",
        "예를 들어 텐서플로우에서 t가 One Hot Encoding이 안되어 있는 경우는 `sparse categorical crossentropy`를 사용하고, One Hot Encoidng이 되어있는 경우에는 `categorical crossentropy`를 쓴다. 이진 분류는 `binary crossentropy`를 사용하는 등의 확인은 필요하다. - 이건 나중에 정리할 예정"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlwexFF9j5qM"
      },
      "source": [
        "## 미니배치 구현하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akz5GLdLk9JJ",
        "outputId": "cb90a287-a19e-4835-f629-25c759af1486"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# 미니배치 선정하기\n",
        "# 훈련 데이터 전체에서 무작위로 10장만 빼내오기\n",
        "\n",
        "train_size = X_train.shape[0] # 전체 훈련 데이터셋 크기 (60,000개)\n",
        "batch_size = 10 # 미니 배치의 사이즈 ( 10개를 1 묶음으로 )\n",
        "batch_mask = np.random.choice(train_size, batch_size) # train_size에서 batch_size만큼의 정수를 무작위로 추출\n",
        "batch_mask"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([25002, 26856, 11723, 33509, 36691, 21111, 28452, 45209, 33743,\n",
              "       26625])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuhwPNd_l1w6"
      },
      "source": [
        "# 배치 데이터 만들기\n",
        "X_batch = X_train[batch_mask] # batch_mask에 위치한 데이터 추출하기\n",
        "y_batch = y_train[batch_mask] # 정답 데이터도 동일한 batch_mask를 이용해서 추출"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsxjW2-smVQF"
      },
      "source": [
        "위의 코드에서는 y라고 되어있지만 실제로는 t(정답)입니다\n",
        "\n",
        "배치용 교차 엔트로피 함수\n",
        "$$\n",
        "E = -\\frac{1}{N}\\sum_n\\;\\sum_{k}t_{nk}\\log{y_{nk}}\n",
        "$$\n",
        "\n",
        "* $N$ : 전체 데이터의 개수( 배치 사이즈 )\n",
        "* $n$ : n 번째 데이터"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gD48HSjfmebW"
      },
      "source": [
        "# ver 1 - t가 One Hot Encoding이 되어있는 경우 + 배치가 없이 데이터가 들어오는 경우(즉 y가 1차원 배열)\n",
        "def cross_entropy_error(y, t):\n",
        "  # 만약에 데이터가 1개만 들어온다면 - 1차원 배열 형태로 데이터가 들어오는 경우 - 배치를 사용하지 않는경우\n",
        "  if y.ndim == 1 : # y가 1차원 배열 - 배치가 없는 경우\n",
        "    # t = t[np.newaxis, :]\n",
        "    t = t.reshape(1, -1)\n",
        "    y = y.reshape(1, -1)\n",
        "  \n",
        "  batch_size = y.shape[0] # N을 구한것\n",
        "\n",
        "  # 배치마다의 loss를 합한다음 batch_size로 나눠주자 - loss의 평균\n",
        "  delta = 1e-7\n",
        "  return -np.sum(t * np.log(y+delta)) / batch_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pWNdSNoo3_J"
      },
      "source": [
        "# ver 2 - t가 One Hot Encoding이 안되어 있는 경우 + 배치가 없이 데이터가 들어오는 경우\n",
        "def sparse_cross_entropy_error(y, t):\n",
        "  if y.ndim == 1:\n",
        "    t = t.reshape(1, t.size)\n",
        "    y = y.reshape(1, y.size)\n",
        "    # size : 스칼라 원소의 개수\n",
        "  \n",
        "  batch_size = y.shape[0]\n",
        "  return -np.sum(np.log(y[np.arange(batch_size), t])) / batch_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wra3P_v2_H0a"
      },
      "source": [
        "```python\n",
        "np.log(y[np.arange(batch_size), t])\n",
        "\n",
        "batch_size = 5\n",
        "t = [2, 7, 0, 9, 8] # OHE이 안되어 있는 상태..\n",
        "\n",
        "np.arange(batch_size) : [0, 1, 2, 3, 4]\n",
        "\n",
        "y[[0, 1, 2, 3, 4], [2, 7, 0, 9, 8]]\n",
        "\n",
        "\n",
        "y[np.arange(batch_size), t] : y[0, 2]\n",
        "                              y[1, 7]\n",
        "                              y[2, 0]\n",
        "                              y[3, 9]\n",
        "                              y[4, 8]\n",
        "\n",
        "y는 현재 batch_size가 5이기 때문에 5개의 배치 데이터에 대한 소프트맥스의 결과물\n",
        "y = [\n",
        "  [0.1, 0.05, 0.8, 0.05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
        "  [0.1, 0.05, 0.8, 0.05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
        "  [0.1, 0.05, 0.8, 0.05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
        "  [0.1, 0.05, 0.8, 0.05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
        "  [0.1, 0.05, 0.8, 0.05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
        "]\n",
        "\n",
        "y[0, 2]의 경우 살펴보기\n",
        "1. np.log(y[np.arange(batch_size), t])\n",
        "2. np.log(y[0, 2])\n",
        "3. np.log(0.8)\n",
        "\n",
        "y[1, 7]\n",
        "y[2, 0]\n",
        "y[3, 9]\n",
        "y[4, 8]\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzQNY2xQrGO6",
        "outputId": "d94253ad-16d2-4c20-efe7-4e341dcdb801"
      },
      "source": [
        "# batch가 없고, OHE이 되어있으면?\n",
        "# t = np.array([0,0,1,0,0]) # (5, )\n",
        "\n",
        "# batch가 없고, OHE도 안되어 있음\n",
        "t = np.array([1]) # (1, )\n",
        "# y는 신경망의 추론단계(순전파)를 지났기 때문에 항상 softmax가 적용된 결과물\n",
        "# 예를 들어 클래스가 3개면... y의 결과물은 3개 - 배치가 없는 경우 - (3, )\n",
        "y = np.array([0.1, 0.7, 0.2])\n",
        "\n",
        "print(t.size) # 1\n",
        "print(y.size) # 3\n",
        "\n",
        "print(t.reshape(1, t.size))\n",
        "print(y.reshape(1, y.size))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "3\n",
            "[[1]]\n",
            "[[0.1 0.7 0.2]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hxj8hM8fr5G1",
        "outputId": "4b0e2c93-667b-4e22-eac3-f58a39617a32"
      },
      "source": [
        "batch_size=5\n",
        "sel = np.array([1, 3, 4])\n",
        "t = np.array([2, 7, 0])\n",
        "\n",
        "y = np.array([\n",
        "  [0.1, 0.05, 0.8, 0.05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
        "  [0.1, 0.05, 0.8, 0.05, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0],\n",
        "  [0.9, 0.05, 0.8, 0.05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
        "  [0.1, 0.05, 0.8, 0.05, 0.0, 0.0, 0.0, 0.0, 0.0, 10],\n",
        "  [0.1, 0.05, 0.8, 0.05, 0.0, 0.0, 0.0, 0.0, 8, 0.0]\n",
        "])\n",
        "\n",
        "y[sel, t]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.8, 0. , 0.1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "honZaMCpCA5J"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}