{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "13. 텍스트 분석을 위한 인코딩",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/koalalovepabro/Deep-Learning/blob/main/13_%ED%85%8D%EC%8A%A4%ED%8A%B8_%EB%B6%84%EC%84%9D%EC%9D%84_%EC%9C%84%ED%95%9C_%EC%9D%B8%EC%BD%94%EB%94%A9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8Xvcsg4HEnM"
      },
      "source": [
        "# 텍스트의 수치화\n",
        "컴퓨터는 텍스트를 인식할 수 없다. 오로지 숫자만 처리가 가능하기 때문에 텍스트를 수치화 시키는 작업을 수행해야 한다.\n",
        "\n",
        "1. Integer Encoding(정수 인코딩)\n",
        "  * 단어 토큰화 또는 형태소 분리 후 각 단어에 대해 **고유한 정수**를 부여\n",
        "  * 중복이 허용되지 않는 모든 단어들의 집합을 만들어야 한다. **단어 집합(Vocabulary)**이라고 한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WR5hj4uBHahX"
      },
      "source": [
        "## Integer Encoding\n",
        "\n",
        "문장을 단어 토큰화 또는 형태소 분리를 진행하여 각 단어 및 형태소를 얻어낼 수 있다. Integer Encoding은 문장을 구성하는 각 형태소에 정수를 부여\n",
        "\n",
        "숫자를 부여하는 기준은 ABC(가나다)순 또는 등장 빈도가 높은 순으로 순서를 구성할 수도 있다.\n",
        "\n",
        "일반적으로는 등장 빈도수가 높으면 앞쪽 번호를 부여한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hcLuMsUHvhV",
        "outputId": "09ce362e-6aa8-4100-8527-508946d58e60"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nA2xwq2wIHKg"
      },
      "source": [
        "## [English] Sentence Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTrj-fhnIOnm"
      },
      "source": [
        "text = \"\"\"Isn't she lovely.\n",
        "Isn't she wonderful.\n",
        "Isn't she precious.\n",
        "Less than one minute old.\n",
        "I never thought through love we'd be.\n",
        "Making one as lovely as she.\n",
        "But isn't she lovely made from love.\n",
        "Isn't she pretty.\n",
        "Truly the angel's best.\n",
        "Boy, I'm so happy.\n",
        "We have been heaven blessed.\n",
        "I can't believe what God has done.\n",
        "Through us he's given life to one.\n",
        "But isn't she lovely made from love.\n",
        "Isn't she lovely.\n",
        "Life and love are the same.\n",
        "Life is Aisha.\n",
        "The meaning of her name.\n",
        "Londie, it could have not been done.\n",
        "Without you who conceived the one.\n",
        "That's so very lovely made from love.\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bhSQ9GSIPre",
        "outputId": "e7b6913c-faa8-469b-822d-b6c614b818be"
      },
      "source": [
        "# sentence tokenization\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "sent_tokens = sent_tokenize(text)\n",
        "print(sent_tokens)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[\"Isn't she lovely.\", \"Isn't she wonderful.\", \"Isn't she precious.\", 'Less than one minute old.', \"I never thought through love we'd be.\", 'Making one as lovely as she.', \"But isn't she lovely made from love.\", \"Isn't she pretty.\", \"Truly the angel's best.\", \"Boy, I'm so happy.\", 'We have been heaven blessed.', \"I can't believe what God has done.\", \"Through us he's given life to one.\", \"But isn't she lovely made from love.\", \"Isn't she lovely.\", 'Life and love are the same.', 'Life is Aisha.', 'The meaning of her name.', 'Londie, it could have not been done.', 'Without you who conceived the one.', \"That's so very lovely made from love.\"]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Zz3YHJoIbfO"
      },
      "source": [
        "## [English] Word Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_ETjHf5Ir_k",
        "outputId": "83f0d32e-5c8a-406a-e0f2-6811b484f15d"
      },
      "source": [
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53ThysaOIs5s"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# 단어 토큰화된 전체 문장을 가지고 있을 배열\n",
        "sentences = []\n",
        "stop_words = set(stopwords.words(\"english\")) # 불용어 중복 제거"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3vyUbX3JLv1",
        "outputId": "ef87dd93-b103-4578-d287-80475205d0d1"
      },
      "source": [
        "# 문장을 하나씩 꺼내서 단어 토큰화\n",
        "for sent in sent_tokens:\n",
        "  word_tokens = word_tokenize(sent) # 단어 토큰화 수행\n",
        "  result = [] # 정제 작업이 완료된 단어를 추가할 배열\n",
        "\n",
        "  ######## 단어 정제 작업 ########\n",
        "  for word in word_tokens: # 단어 토큰에서 단어를 하나씩 추출해 주기\n",
        "    # 소문자화\n",
        "    word = word.lower() # 모든 단어를 소문자화 하여 정규화\n",
        "\n",
        "    \n",
        "    if word not in stop_words: # 불용어 처리\n",
        "      # 단어 길이가 3개 이상인 단어만 사용\n",
        "      if len(word) > 2 :\n",
        "        result.append(word)\n",
        "  ##############################\n",
        "  sentences.append(result)\n",
        "\n",
        "print(sentences)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[\"n't\", 'lovely'], [\"n't\", 'wonderful'], [\"n't\", 'precious'], ['less', 'one', 'minute', 'old'], ['never', 'thought', 'love'], ['making', 'one', 'lovely'], [\"n't\", 'lovely', 'made', 'love'], [\"n't\", 'pretty'], ['truly', 'angel', 'best'], ['boy', 'happy'], ['heaven', 'blessed'], [\"n't\", 'believe', 'god', 'done'], ['given', 'life', 'one'], [\"n't\", 'lovely', 'made', 'love'], [\"n't\", 'lovely'], ['life', 'love'], ['life', 'aisha'], ['meaning', 'name'], ['londie', 'could', 'done'], ['without', 'conceived', 'one'], ['lovely', 'made', 'love']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfT92F0UJXOy"
      },
      "source": [
        "## [English] 단어 집합 만들기 ( Python )\n",
        "단어 집합이란? 중복을 제거한 단어들의 집합"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwUqCAynKpE3",
        "outputId": "55d76a35-aa4d-4ff6-f18c-1802dae8a860"
      },
      "source": [
        "# 각 배열에 등장한 횟수가 많을 수록 앞 번호에 배치\n",
        "# 1. 문장 별로 모여있는 단어들을 하나로 풀어서 합치기\n",
        "words = sum(sentences, []) # sentences에 들어있는 모든 배열을 비어있는 배열에 합치는 역할(extends)\n",
        "print(words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[\"n't\", 'lovely', \"n't\", 'wonderful', \"n't\", 'precious', 'less', 'one', 'minute', 'old', 'never', 'thought', 'love', 'making', 'one', 'lovely', \"n't\", 'lovely', 'made', 'love', \"n't\", 'pretty', 'truly', 'angel', 'best', 'boy', 'happy', 'heaven', 'blessed', \"n't\", 'believe', 'god', 'done', 'given', 'life', 'one', \"n't\", 'lovely', 'made', 'love', \"n't\", 'lovely', 'life', 'love', 'life', 'aisha', 'meaning', 'name', 'londie', 'could', 'done', 'without', 'conceived', 'one', 'lovely', 'made', 'love']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XciottbEK-je",
        "outputId": "8512e37d-ee7c-4110-d8b5-418fb48ae3ad"
      },
      "source": [
        "# 2. 빈도수를 센 다음 배치\n",
        "from collections import Counter # 횟수 세기 용도\n",
        "vocab = Counter(words) # Counter 모듈을 활용하면 단어의 모든 빈도수를 손쉽게 계산 가능\n",
        "\n",
        "print(vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counter({\"n't\": 8, 'lovely': 6, 'love': 5, 'one': 4, 'made': 3, 'life': 3, 'done': 2, 'wonderful': 1, 'precious': 1, 'less': 1, 'minute': 1, 'old': 1, 'never': 1, 'thought': 1, 'making': 1, 'pretty': 1, 'truly': 1, 'angel': 1, 'best': 1, 'boy': 1, 'happy': 1, 'heaven': 1, 'blessed': 1, 'believe': 1, 'god': 1, 'given': 1, 'aisha': 1, 'meaning': 1, 'name': 1, 'londie': 1, 'could': 1, 'without': 1, 'conceived': 1})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZ6fgw4JLVhu"
      },
      "source": [
        "빈도 내림차순으로 정렬"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWatCZ0rLh-N",
        "outputId": "c97aadca-9ede-4040-a502-358a67d2de80"
      },
      "source": [
        "vocab_items = vocab.items()\n",
        "vocab_items"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_items([(\"n't\", 8), ('lovely', 6), ('wonderful', 1), ('precious', 1), ('less', 1), ('one', 4), ('minute', 1), ('old', 1), ('never', 1), ('thought', 1), ('love', 5), ('making', 1), ('made', 3), ('pretty', 1), ('truly', 1), ('angel', 1), ('best', 1), ('boy', 1), ('happy', 1), ('heaven', 1), ('blessed', 1), ('believe', 1), ('god', 1), ('done', 2), ('given', 1), ('life', 3), ('aisha', 1), ('meaning', 1), ('name', 1), ('londie', 1), ('could', 1), ('without', 1), ('conceived', 1)])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZSmlOYeLqhU",
        "outputId": "fc8b0f61-2cee-4c6c-8636-1b1ec41bac90"
      },
      "source": [
        "# 빈도수가 높은 순서대로 정렬\n",
        "vocab_sorted = sorted(vocab_items, key = lambda x : x[1], reverse=True )\n",
        "print(vocab_sorted)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(\"n't\", 8), ('lovely', 6), ('love', 5), ('one', 4), ('made', 3), ('life', 3), ('done', 2), ('wonderful', 1), ('precious', 1), ('less', 1), ('minute', 1), ('old', 1), ('never', 1), ('thought', 1), ('making', 1), ('pretty', 1), ('truly', 1), ('angel', 1), ('best', 1), ('boy', 1), ('happy', 1), ('heaven', 1), ('blessed', 1), ('believe', 1), ('god', 1), ('given', 1), ('aisha', 1), ('meaning', 1), ('name', 1), ('londie', 1), ('could', 1), ('without', 1), ('conceived', 1)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLc7ayf7ML5R"
      },
      "source": [
        "높은 빈도수를 가진 단어일 수록 낮은 정수 인덱스를 부여 ( 앞쪽에 배치 )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ij8BHJNZMfiF",
        "outputId": "e852b719-880e-4400-8a3a-a563a0b7d7c1"
      },
      "source": [
        "word2idx = {} # 비어있는 딕셔너리\n",
        "i = 0\n",
        "\n",
        "for word, frequency in vocab_sorted:\n",
        "\n",
        "  if frequency > 1 : # 정제 작업. 빈도수가 너무 작은 단어는 제외\n",
        "    i = i+1\n",
        "    word2idx[word] = i # 딕셔너리에 단어와 정수(단어의 인덱스) 추가\n",
        "\n",
        "print(word2idx)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\"n't\": 1, 'lovely': 2, 'love': 3, 'one': 4, 'made': 5, 'life': 6, 'done': 7}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAwJC_oSM84p"
      },
      "source": [
        "빈도수가 가장 높은 상위 n개만 선택해서 단어집합으로 사용하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dnph_SuENXyB",
        "outputId": "efa5d3d4-d3dc-4dad-a0ae-01839355c21d"
      },
      "source": [
        "# 단어 집합 상위 5개의 단어만 사용하겠다. (사용할 단어집합의 크기)\n",
        "#   딥러닝 수행 시 사용할 단어의 개수가 됩니다. (반드시 외워두세요)\n",
        "vocab_size = 5 # 단어 집합의 크기\n",
        "\n",
        "# 단어 집합의 인덱스를 구해오기\n",
        "word_frequency = [ w for w, c in word2idx.items() if c >= vocab_size + 1]\n",
        "print(word_frequency) # 단어 집합에서 제외할 단어들"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['life', 'done']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cC9cHDxcNyMz",
        "outputId": "5d1c5850-00b9-49f9-c7a6-2b49c1c588df"
      },
      "source": [
        "# 단어 사전에서 버릴 단어들 제거\n",
        "for w in word_frequency:\n",
        "  del word2idx[w]\n",
        "\n",
        "print(word2idx)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\"n't\": 1, 'lovely': 2, 'love': 3, 'one': 4, 'made': 5}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IiCoPKrOBxF"
      },
      "source": [
        "## [English] 인코딩 수행하기\n",
        "* 텍스트로 이루어진 단어를 정수로 표현하는 것을 **인코딩**이라고 한다.\n",
        "* 정수를 텍스트로 이루어진 단어로 표현하는 것을 **디코딩**이라고 한다.\n",
        "\n",
        "Transformer, Seq2Seq, Attention(바다나우 어텐션), BERT 등을 배우시게 되면 인코딩과 디코딩 작업용해서 텍스트를 분류할 수도 있고, 생성할 수도 있어요\n",
        "\n",
        "이 때 생성할 때 사용되어지는 기법이 디코딩"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iyoOaVrOOR1n",
        "outputId": "8a61ba5c-b86d-4259-d01c-dd13e182d74c"
      },
      "source": [
        "# UNK(OOV) 토큰 만들기\n",
        "word2idx[\"<oov>\"] = 6\n",
        "print(word2idx)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\"n't\": 1, 'lovely': 2, 'love': 3, 'one': 4, 'made': 5, '<oov>': 6}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tbApP4kBO2gE",
        "outputId": "591c20d5-e8f7-4b4a-e029-f2f26b831f02"
      },
      "source": [
        "# 인코딩된 데이터를 저장하기 위한 배열\n",
        "encoded = []\n",
        "\n",
        "for s in sentences:\n",
        "  # 임시로 인코딩된 내용을 저장할 배열\n",
        "  temp = []\n",
        "\n",
        "  # 문장에서 단어 토큰을 하나씩 꺼내기\n",
        "  for w in s:\n",
        "    if w in word2idx: # 단어가 사전에 있으면\n",
        "      temp.append(word2idx[w]) # 단어에 해당하는 정수를 temp에 추가\n",
        "    else:\n",
        "      temp.append(word2idx[\"<oov>\"]) # 단어 집합에 없는 단어라면 oov에 해당하는 정수를 찾아서 추가\n",
        "  \n",
        "  encoded.append(temp)\n",
        "\n",
        "print(\"변환 전 : \", sentences[:5])\n",
        "print(\"변환 후 : \", encoded[:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "변환 전 :  [[\"n't\", 'lovely'], [\"n't\", 'wonderful'], [\"n't\", 'precious'], ['less', 'one', 'minute', 'old'], ['never', 'thought', 'love']]\n",
            "변환 후 :  [[1, 2], [1, 6], [1, 6], [6, 4, 6, 6], [6, 6, 3]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3e0YGcJPtBx"
      },
      "source": [
        "## [English] Vocab & Integer Encoding (Tensorflow)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "he-DbnKwPAf2",
        "outputId": "5fe14384-600a-43a5-fecb-bf974222bc7b"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "t = Tokenizer()\n",
        "\n",
        "# fit_on_texts() 함수에 코퍼스(sentences)를 집어 넣으면 바로 빈도수를 기준으로 단어 집합을 만들어 준다.\n",
        "t.fit_on_texts(sentences) # 형태소 분리의 결과가 들어간다. 이 때 형태소 분리의 결과는 항상 2차원 배열이어야만 한다.\n",
        "\n",
        "# 생성된 단어집합 확인\n",
        "print(t.word_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\"n't\": 1, 'lovely': 2, 'love': 3, 'one': 4, 'made': 5, 'life': 6, 'done': 7, 'wonderful': 8, 'precious': 9, 'less': 10, 'minute': 11, 'old': 12, 'never': 13, 'thought': 14, 'making': 15, 'pretty': 16, 'truly': 17, 'angel': 18, 'best': 19, 'boy': 20, 'happy': 21, 'heaven': 22, 'blessed': 23, 'believe': 24, 'god': 25, 'given': 26, 'aisha': 27, 'meaning': 28, 'name': 29, 'londie': 30, 'could': 31, 'without': 32, 'conceived': 33}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAmjY_yBQirq",
        "outputId": "c39a5291-fa2d-4d5c-93ed-1034ef4d714f"
      },
      "source": [
        "# 단어의 빈도수 확인하기\n",
        "print(t.word_counts)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OrderedDict([(\"n't\", 8), ('lovely', 6), ('wonderful', 1), ('precious', 1), ('less', 1), ('one', 4), ('minute', 1), ('old', 1), ('never', 1), ('thought', 1), ('love', 5), ('making', 1), ('made', 3), ('pretty', 1), ('truly', 1), ('angel', 1), ('best', 1), ('boy', 1), ('happy', 1), ('heaven', 1), ('blessed', 1), ('believe', 1), ('god', 1), ('done', 2), ('given', 1), ('life', 3), ('aisha', 1), ('meaning', 1), ('name', 1), ('londie', 1), ('could', 1), ('without', 1), ('conceived', 1)])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNyrjaEzQqRn",
        "outputId": "d32daffe-aed2-4d5c-b4a1-cf15f9902eba"
      },
      "source": [
        "# 인코딩 수행하기(texts_to_sequences)\n",
        "print(t.texts_to_sequences(sentences))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1, 2], [1, 8], [1, 9], [10, 4, 11, 12], [13, 14, 3], [15, 4, 2], [1, 2, 5, 3], [1, 16], [17, 18, 19], [20, 21], [22, 23], [1, 24, 25, 7], [26, 6, 4], [1, 2, 5, 3], [1, 2], [6, 3], [6, 27], [28, 29], [30, 31, 7], [32, 33, 4], [2, 5, 3]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjHE_zmhQzQI",
        "outputId": "aa4c2bab-73a5-4f23-e8c6-795ab9329ad6"
      },
      "source": [
        "# 디코딩 수행하기(sequences_to_texts)\n",
        "print(t.sequences_to_texts([[1, 12],\n",
        "                            [1, 17, 22]]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[\"n't old\", \"n't truly heaven\"]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12kTx8rsQ99j"
      },
      "source": [
        "## [Korean] 토큰화 및 정수 인코딩을 Tensorflow로 구현"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4d7arrhLUW0R",
        "outputId": "12dce62a-b67b-491d-c188-538af60d9dff"
      },
      "source": [
        "!pip install konlpy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting konlpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/0e/f385566fec837c0b83f216b2da65db9997b35dd675e107752005b7d392b1/konlpy-0.5.2-py2.py3-none-any.whl (19.4MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4MB 5.9MB/s \n",
            "\u001b[?25hCollecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Collecting JPype1>=0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/a5/9781e2ef4ca92d09912c4794642c1653aea7607f473e156cf4d423a881a1/JPype1-1.2.1-cp37-cp37m-manylinux2010_x86_64.whl (457kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 29.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Collecting beautifulsoup4==4.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 9.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Installing collected packages: colorama, JPype1, beautifulsoup4, konlpy\n",
            "  Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "Successfully installed JPype1-1.2.1 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Up30HYx2UZ2s"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import urllib.request\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdB2PZokU0Ld",
        "outputId": "a86b6039-77e9-48c3-c5fe-e239a379b5f8"
      },
      "source": [
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt\", filename=\"ratings_test.txt\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('ratings_test.txt', <http.client.HTTPMessage at 0x7f6723ad7b50>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yiM9q9gjU4Mx",
        "outputId": "10a90262-7e60-49a0-d311-0d4bb6ea3fc2"
      },
      "source": [
        "train_data = pd.read_table(\"ratings_test.txt\", encoding='utf-8')\n",
        "train_data.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 50000 entries, 0 to 49999\n",
            "Data columns (total 3 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   id        50000 non-null  int64 \n",
            " 1   document  49997 non-null  object\n",
            " 2   label     50000 non-null  int64 \n",
            "dtypes: int64(2), object(1)\n",
            "memory usage: 1.1+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "Iy1Ev8tNVIgh",
        "outputId": "e93de71d-4e4e-422d-86d8-edf107dc5702"
      },
      "source": [
        "train_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>document</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6270596</td>\n",
              "      <td>굳 ㅋ</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9274899</td>\n",
              "      <td>GDNTOPCLASSINTHECLUB</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8544678</td>\n",
              "      <td>뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6825595</td>\n",
              "      <td>지루하지는 않은데 완전 막장임... 돈주고 보기에는....</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6723715</td>\n",
              "      <td>3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id                                           document  label\n",
              "0  6270596                                                굳 ㅋ      1\n",
              "1  9274899                               GDNTOPCLASSINTHECLUB      0\n",
              "2  8544678             뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아      0\n",
              "3  6825595                   지루하지는 않은데 완전 막장임... 돈주고 보기에는....      0\n",
              "4  6723715  3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQIamaYFVe07"
      },
      "source": [
        "1. nan값 제거\n",
        "2. 중복 문장 제거\n",
        "3. 특수문자 및 영어 제거"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VIywTJ2BVrAN",
        "outputId": "7c7dcace-cfac-4137-ea6f-db5ec52fdcd7"
      },
      "source": [
        "# 중복되지 않은 데이터의 개수 확인\n",
        "train_data['document'].nunique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49157"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-bGtVbZV1nE"
      },
      "source": [
        "# 중복 데이터 제거, nan값 제거\n",
        "train_data.drop_duplicates(subset=['document'], inplace=True)\n",
        "train_data = train_data.dropna(how='any') # nan값이 존재하는 행을 제거"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "CqsPvCEsWFYR",
        "outputId": "1dfd80a7-4767-4438-8d7c-dc65dfe6bb2e"
      },
      "source": [
        "# 정규식을 활용해서 한글만 추출( 영문, 특수문자 제거 )\n",
        "train_data['document'] = train_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\", \"\") # 한글 및 공백이 아닌 문자는 모두 \"\"\n",
        "train_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>document</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6270596</td>\n",
              "      <td>굳 ㅋ</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9274899</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8544678</td>\n",
              "      <td>뭐야 이 평점들은 나쁘진 않지만 점 짜리는 더더욱 아니잖아</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6825595</td>\n",
              "      <td>지루하지는 않은데 완전 막장임 돈주고 보기에는</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6723715</td>\n",
              "      <td>만 아니었어도 별 다섯 개 줬을텐데 왜 로 나와서 제 심기를 불편하게 하죠</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id                                   document  label\n",
              "0  6270596                                        굳 ㅋ      1\n",
              "1  9274899                                                 0\n",
              "2  8544678           뭐야 이 평점들은 나쁘진 않지만 점 짜리는 더더욱 아니잖아      0\n",
              "3  6825595                  지루하지는 않은데 완전 막장임 돈주고 보기에는      0\n",
              "4  6723715  만 아니었어도 별 다섯 개 줬을텐데 왜 로 나와서 제 심기를 불편하게 하죠      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezHkDHWMWiwy"
      },
      "source": [
        "비어있는 문자열 정제"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QtFjeCDWy1X",
        "outputId": "04abe2a1-f55d-4ccb-b147-ae606bd6576f"
      },
      "source": [
        "# 비어있는 문자열을 강제로 nan값으로 만들고, nan을 제거\n",
        "train_data['document'].replace(\"\", np.nan, inplace=True)\n",
        "train_data.isnull().sum() # nan값이 몇개가 있는지 개수 세기"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id            0\n",
              "document    162\n",
              "label         0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "CAc3Ly9dW_14",
        "outputId": "a2d3f206-ac1c-4660-ff47-74dc584f2471"
      },
      "source": [
        "train_data = train_data.dropna(how='any')\n",
        "train_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>document</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6270596</td>\n",
              "      <td>굳 ㅋ</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8544678</td>\n",
              "      <td>뭐야 이 평점들은 나쁘진 않지만 점 짜리는 더더욱 아니잖아</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6825595</td>\n",
              "      <td>지루하지는 않은데 완전 막장임 돈주고 보기에는</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6723715</td>\n",
              "      <td>만 아니었어도 별 다섯 개 줬을텐데 왜 로 나와서 제 심기를 불편하게 하죠</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>7898805</td>\n",
              "      <td>음악이 주가 된 최고의 음악영화</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id                                   document  label\n",
              "0  6270596                                        굳 ㅋ      1\n",
              "2  8544678           뭐야 이 평점들은 나쁘진 않지만 점 짜리는 더더욱 아니잖아      0\n",
              "3  6825595                  지루하지는 않은데 완전 막장임 돈주고 보기에는      0\n",
              "4  6723715  만 아니었어도 별 다섯 개 줬을텐데 왜 로 나와서 제 심기를 불편하게 하죠      0\n",
              "5  7898805                          음악이 주가 된 최고의 음악영화      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sy7Lx2EVXMgc"
      },
      "source": [
        "Stemming 작업"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IK3hs0iXYzi"
      },
      "source": [
        "from konlpy.tag import Okt\n",
        "okt = Okt()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qsm1Kn_eXgcC",
        "outputId": "7be3c80a-a4a8-49dd-da0f-0c5c5e0d97dd"
      },
      "source": [
        "# okt 테스트 하기\n",
        "sample_text = \"뭐야 이 평점들은 나쁘진 않지만 점 짜리는 더더욱 아니잖아\"\n",
        "print(okt.morphs(sample_text, stem=True))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['뭐', '야', '이', '평점', '들', '은', '나쁘다', '않다', '점', '짜다', '리', '는', '더', '더욱', '아니다']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RhQ8NdfqXss5"
      },
      "source": [
        "불용어(stopwords) 선정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40tL844SX372"
      },
      "source": [
        "stop_words = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다', '것', '게']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZkaXJZniYRE0",
        "outputId": "5d56ae3f-8e6f-4f89-cd39-83b4bf09a0ba"
      },
      "source": [
        "X_train = []\n",
        "\n",
        "for sentence in train_data['document']:\n",
        "  temp_X = []\n",
        "  temp_X = okt.morphs(sentence, stem=True) # 토큰화\n",
        "  temp_X = [word for word in temp_X if not word in stop_words] # 불용어 제거\n",
        "  \n",
        "  X_train.append(temp_X)\n",
        "\n",
        "X_train[:3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['굳다', 'ㅋ'],\n",
              " ['뭐', '야', '평점', '나쁘다', '않다', '점', '짜다', '리', '더', '더욱', '아니다'],\n",
              " ['지루하다', '않다', '완전', '막장', '임', '돈', '주다', '보기', '에는']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4I_oPgDYvfi"
      },
      "source": [
        "t = Tokenizer()\n",
        "t.fit_on_texts(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzaDfv9XbP8o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6c3bb43-1f3c-4248-f739-3f45c1a69be0"
      },
      "source": [
        "t.texts_to_sequences(X_train)[:3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[611, 89],\n",
              " [62, 165, 23, 392, 19, 20, 277, 773, 42, 858, 17],\n",
              " [64, 19, 87, 377, 107, 109, 58, 148, 243]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfTbsmpcbTPc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}